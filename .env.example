# .env.example
# Copy this file to .env and update with your configuration

# LLM Configuration
OPENAI_API_KEY=sk-your-api-key-here
OPENAI_MODEL=gpt-4o-mini
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_VERIFY_SSL=true
OPENAI_TIMEOUT=60
OPENAI_MAX_RETRIES=3

# File Storage
FILES_ROOT=/app/files
UPLOAD_DIR=/app/files/uploaded_files
PROCESSED_DIR=/app/files/processed_files
BATCH_DIR=/app/files/batch_files
MAX_FILE_SIZE=52428800

# Quality Thresholds (defaults)
DEFAULT_CONVERSION_THRESHOLD=70
DEFAULT_CLARITY_THRESHOLD=7
DEFAULT_COMPLETENESS_THRESHOLD=7
DEFAULT_RELEVANCE_THRESHOLD=7
DEFAULT_MARKDOWN_THRESHOLD=7

# API Settings
DEBUG=false
CORS_ORIGINS=["http://localhost:3000","http://127.0.0.1:3000"]
# Allow any localhost HTTP origin (regex). Useful for dev when ports change.
# Example matches: http://localhost:3000, http://127.0.0.1:5173
CORS_ORIGIN_REGEX=^http://(localhost|127\.0\.0\.1)(:\\d+)?$

# Alternative LLM Configurations (uncomment and modify as needed)

# Local LLM (Ollama)
# OPENAI_BASE_URL=http://localhost:11434/v1
# OPENAI_API_KEY=ollama
# OPENAI_MODEL=llama3.1:8b
# OPENAI_VERIFY_SSL=false

# OpenWebUI
# OPENAI_BASE_URL=http://localhost:3000/v1
# OPENAI_API_KEY=your-openwebui-api-key
# OPENAI_MODEL=gpt-3.5-turbo

# LM Studio
# OPENAI_BASE_URL=http://localhost:1234/v1
# OPENAI_API_KEY=lm-studio
# OPENAI_MODEL=your-model-name


EXTRACTOR_BASE_URL=http://extraction:8000
EXTRACTOR_EXTRACT_PATH=/v1/extract
# Optional:
EXTRACTOR_API_KEY=your-token
EXTRACTOR_TIMEOUT=120
EXTRACTOR_MAX_RETRIES=2
EXTRACTOR_VERIFY_SSL=true


# ============================================================================
# EXTRACTION SERVICE
# ============================================================================
# Port mapping for extraction-service container
EXTRACTION_SERVICE_PORT=8010

# (The following are already present in the repo and are reused by this service)
OCR_LANG=eng
OCR_PSM=3
# FILES_ROOT=/app/files
# UPLOAD_DIR=/app/files/uploaded_files
# PROCESSED_DIR=/app/files/processed_files
# BATCH_DIR=/app/files/batch_files
# MAX_FILE_SIZE=52428800

# CORS for local frontend
# CORS_ORIGINS=["http://localhost:3000"]
