# ============================================================================
# Curatore v2 - Environment Configuration
# ============================================================================
# Copy this file to .env and customize for your deployment.
# All settings have sensible defaults; customize as needed for your use case.
# ============================================================================

# ============================================================================
# API / CORS SETTINGS
# ============================================================================

# DEBUG: Enable verbose logging and development helpers
#   - true: Detailed logs, stack traces, dev tools enabled
#   - false: Production mode with minimal logging
DEBUG=false

# CORS_ORIGINS: Allowed origins for cross-origin requests (JSON array format)
#   Example: ["http://localhost:3000","http://127.0.0.1:3000"]
CORS_ORIGINS=["http://localhost:3000"]


# ============================================================================
# LLM CONFIGURATION
# ============================================================================
# The LLM is used for document quality evaluation (clarity, completeness, etc.)

# OPENAI_API_KEY: Your API key for the LLM service
#   - Required for LLM evaluation features
#   - Supports OpenAI, Ollama, OpenWebUI, LM Studio, and compatible endpoints
OPENAI_API_KEY=put-your-openai-api-key-here

# OPENAI_MODEL: Model name to use for evaluations
#   - OpenAI: gpt-4o-mini, gpt-4o, gpt-4-turbo, gpt-3.5-turbo
#   - Ollama: llama3, mistral, mixtral, etc.
#   - Recommendation: gpt-4o-mini for best cost/performance balance
OPENAI_MODEL=gpt-4o-mini

# OPENAI_BASE_URL: LLM API endpoint
#   - OpenAI: https://api.openai.com/v1
#   - Ollama: http://localhost:11434/v1
#   - OpenWebUI: http://localhost:3000/v1
#   - LM Studio: http://localhost:1234/v1
OPENAI_BASE_URL=https://api.openai.com/v1

# OPENAI_VERIFY_SSL: Verify SSL certificates for LLM API calls
#   - true: Verify certificates (recommended for production)
#   - false: Skip verification (useful for self-signed certs in dev)
OPENAI_VERIFY_SSL=true

# OPENAI_TIMEOUT: Request timeout in seconds for LLM API calls
#   - Default: 60 seconds
#   - Increase for slower models or large documents
OPENAI_TIMEOUT=60

# OPENAI_MAX_RETRIES: Number of retry attempts for failed LLM API calls
#   - Default: 3 retries
#   - Set to 0 to disable retries
OPENAI_MAX_RETRIES=3


# ============================================================================
# OCR CONFIGURATION
# ============================================================================
# Used by extraction service for image-based PDFs and scanned documents

# OCR_LANG: Tesseract OCR language code
#   - eng: English
#   - spa: Spanish
#   - fra: French
#   - deu: German
#   - Multiple languages: eng+spa+fra
#   - Full list: https://github.com/tesseract-ocr/tessdata
OCR_LANG=eng

# OCR_PSM: Tesseract Page Segmentation Mode
#   - 3: Fully automatic page segmentation (default, recommended)
#   - 6: Uniform block of text
#   - 11: Sparse text (find as much text as possible)
#   - Full list: https://tesseract-ocr.github.io/tessdoc/ImproveQuality.html#page-segmentation-method
OCR_PSM=3


# ============================================================================
# FILE STORAGE CONFIGURATION
# ============================================================================
# Paths are INSIDE containers; docker-compose bind-mounts ./files -> /app/files

# FILES_ROOT: Root directory for all file storage
FILES_ROOT=/app/files

# UPLOAD_DIR: Directory for user-uploaded files
UPLOAD_DIR=/app/files/uploaded_files

# PROCESSED_DIR: Directory for processed markdown output
PROCESSED_DIR=/app/files/processed_files

# BATCH_DIR: Directory for operator-provided bulk/test inputs
BATCH_DIR=/app/files/batch_files

# MAX_FILE_SIZE: Maximum upload size in bytes
#   - Default: 52428800 (50 MB)
#   - Formula: bytes = MB × 1024 × 1024
MAX_FILE_SIZE=52428800


# ============================================================================
# HIERARCHICAL STORAGE CONFIGURATION
# ============================================================================
# Organization-based file hierarchy with batch/adhoc groupings

# USE_HIERARCHICAL_STORAGE: Enable new hierarchical file organization
#   - true: Use organization-based folders (organizations/{org_id}/batches|adhoc)
#   - false: Use legacy flat structure (uploaded_files/, processed_files/)
#   - Default: true
#   - Recommended: true for new deployments
USE_HIERARCHICAL_STORAGE=true

# TEMP_DIR: Directory for temporary processing files
#   - Used during document processing
#   - Automatically cleaned up after job completion
#   - Default: /app/files/temp
TEMP_DIR=/app/files/temp

# DEDUPE_DIR: Directory for content-addressable deduplicated file storage
#   - Stores unique file content once, referenced by multiple documents
#   - Organized by hash (first 2 chars for sharding)
#   - Default: /app/files/dedupe
DEDUPE_DIR=/app/files/dedupe


# ============================================================================
# FILE RETENTION CONFIGURATION
# ============================================================================
# Automatic cleanup of expired files based on age

# FILE_RETENTION_UPLOADED_DAYS: Days to retain uploaded files
#   - Default: 7 days
#   - Files older than this will be deleted by cleanup task
FILE_RETENTION_UPLOADED_DAYS=7

# FILE_RETENTION_PROCESSED_DAYS: Days to retain processed markdown files
#   - Default: 30 days
#   - Processed files kept longer than uploads
FILE_RETENTION_PROCESSED_DAYS=30

# FILE_RETENTION_BATCH_DAYS: Days to retain batch files and metadata
#   - Default: 14 days
#   - Applies to entire batch folder and metadata.json
FILE_RETENTION_BATCH_DAYS=14

# FILE_RETENTION_TEMP_HOURS: Hours to retain temporary processing files
#   - Default: 24 hours
#   - Temp files should be cleaned up quickly
FILE_RETENTION_TEMP_HOURS=24


# ============================================================================
# FILE CLEANUP CONFIGURATION
# ============================================================================
# Scheduled cleanup task settings

# FILE_CLEANUP_ENABLED: Enable automatic file cleanup
#   - true: Run scheduled cleanup task (respects schedule below)
#   - false: Disable automatic cleanup (manual only)
#   - Default: true
FILE_CLEANUP_ENABLED=true

# FILE_CLEANUP_SCHEDULE_CRON: Cleanup schedule in cron format
#   - Format: "minute hour day month day_of_week"
#   - Default: "0 2 * * *" (daily at 2 AM UTC)
#   - Examples:
#     - "0 2 * * *": Daily at 2 AM
#     - "0 */6 * * *": Every 6 hours
#     - "0 0 * * 0": Weekly on Sunday at midnight
FILE_CLEANUP_SCHEDULE_CRON=0 2 * * *

# FILE_CLEANUP_BATCH_SIZE: Files to process per cleanup batch
#   - Default: 1000 files
#   - Prevents memory issues with large cleanups
#   - Higher = faster cleanup but more memory usage
FILE_CLEANUP_BATCH_SIZE=1000

# FILE_CLEANUP_DRY_RUN: Run cleanup in dry-run mode (preview only)
#   - true: Log what would be deleted without actually deleting
#   - false: Actually delete expired files
#   - Default: false
#   - Useful for testing retention policies
FILE_CLEANUP_DRY_RUN=false


# ============================================================================
# FILE DEDUPLICATION CONFIGURATION
# ============================================================================
# Content-based file deduplication with SHA-256 hashing

# FILE_DEDUPLICATION_ENABLED: Enable duplicate file detection
#   - true: Detect duplicates and store only one copy
#   - false: Store all files separately (no deduplication)
#   - Default: true
#   - Saves storage space when same file uploaded multiple times
FILE_DEDUPLICATION_ENABLED=true

# FILE_DEDUPLICATION_STRATEGY: How to handle deduplicated files
#   - symlink: Create symbolic links to dedupe storage (recommended, space efficient)
#   - copy: Copy files from dedupe storage (compatible, uses more space)
#   - reference: Store only reference (most efficient, requires lookup)
#   - Default: symlink
FILE_DEDUPLICATION_STRATEGY=symlink

# DEDUPE_HASH_ALGORITHM: Hash algorithm for content deduplication
#   - Default: sha256
#   - Options: md5, sha1, sha256, sha512
#   - Recommendation: sha256 for security and collision resistance
DEDUPE_HASH_ALGORITHM=sha256

# DEDUPE_MIN_FILE_SIZE: Minimum file size (bytes) to deduplicate
#   - Default: 1024 (1 KB)
#   - Files smaller than this are not deduplicated (overhead not worth it)
#   - Increase for better performance with many small files
DEDUPE_MIN_FILE_SIZE=1024


# ============================================================================
# QUALITY THRESHOLDS
# ============================================================================
# All thresholds must be met for a document to be marked "RAG Ready"

# DEFAULT_CONVERSION_THRESHOLD: Conversion quality score (0-100 scale)
#   - 70+: Good quality extraction
#   - 80+: Excellent quality extraction
#   - 90+: Near-perfect extraction
DEFAULT_CONVERSION_THRESHOLD=70

# DEFAULT_CLARITY_THRESHOLD: Document clarity score (1-10 scale)
#   - How clear and understandable is the content?
#   - Evaluated by LLM
DEFAULT_CLARITY_THRESHOLD=7

# DEFAULT_COMPLETENESS_THRESHOLD: Content completeness score (1-10 scale)
#   - How complete is the extracted content?
#   - Evaluated by LLM
DEFAULT_COMPLETENESS_THRESHOLD=7

# DEFAULT_RELEVANCE_THRESHOLD: Content relevance score (1-10 scale)
#   - How relevant is the content for RAG use cases?
#   - Evaluated by LLM
DEFAULT_RELEVANCE_THRESHOLD=7

# DEFAULT_MARKDOWN_THRESHOLD: Markdown quality score (1-10 scale)
#   - How well-formatted is the markdown output?
#   - Evaluated by LLM
DEFAULT_MARKDOWN_THRESHOLD=7


# ============================================================================
# CELERY / REDIS CONFIGURATION
# ============================================================================
# Background job processing and task queue management

# CELERY_DEFAULT_QUEUE: Queue name for processing tasks
CELERY_DEFAULT_QUEUE=processing

# CELERY_BROKER_URL: Redis URL for task queue broker
#   - Format: redis://hostname:port/db
#   - Default uses service name from docker-compose
CELERY_BROKER_URL=redis://redis:6379/0

# CELERY_RESULT_BACKEND: Redis URL for storing task results
#   - Uses separate database (1) from broker (0)
CELERY_RESULT_BACKEND=redis://redis:6379/1


# ============================================================================
# JOB MANAGEMENT CONFIGURATION
# ============================================================================
# Settings for batch job processing, concurrency limits, and retention policies

# DEFAULT_JOB_CONCURRENCY_LIMIT: Maximum concurrent jobs per organization
#   - Default: 3 jobs
#   - Prevents resource exhaustion and ensures fair sharing
#   - Admins can override per organization via settings
#   - Range: 1-10 recommended
DEFAULT_JOB_CONCURRENCY_LIMIT=3

# DEFAULT_JOB_RETENTION_DAYS: Days to retain completed jobs
#   - Default: 30 days
#   - Completed jobs older than this will be auto-deleted by cleanup task
#   - Options: 7, 30, 90, or 0 for indefinite retention
#   - Admins can override per organization via settings
DEFAULT_JOB_RETENTION_DAYS=30

# JOB_CLEANUP_ENABLED: Enable automatic cleanup of expired jobs
#   - true: Run scheduled cleanup task (respects schedule below)
#   - false: Disable automatic cleanup (manual only)
#   - Default: true
#   - Cleanup deletes job records and associated files
JOB_CLEANUP_ENABLED=true

# JOB_CLEANUP_SCHEDULE_CRON: Job cleanup schedule in cron format
#   - Format: "minute hour day month day_of_week"
#   - Default: "0 3 * * *" (daily at 3 AM UTC)
#   - Examples:
#     - "0 3 * * *": Daily at 3 AM
#     - "0 */12 * * *": Every 12 hours
#     - "0 2 * * 0": Weekly on Sunday at 2 AM
JOB_CLEANUP_SCHEDULE_CRON=0 3 * * *

# JOB_CANCELLATION_TIMEOUT: Timeout in seconds for job cancellation verification
#   - Default: 30 seconds
#   - How long to wait for Celery tasks to terminate after revoke
#   - Increase if workers need more time for graceful shutdown
#   - After timeout, logs warning but continues with cleanup
JOB_CANCELLATION_TIMEOUT=30

# JOB_STATUS_POLL_INTERVAL: Polling interval in seconds for job status updates
#   - Default: 2 seconds
#   - Frontend polls at this interval for active jobs
#   - Lower = more real-time but higher load
#   - Higher = less load but slower updates
#   - Recommended: 2-5 seconds
JOB_STATUS_POLL_INTERVAL=2


# ============================================================================
# EXTRACTION SERVICE CONFIGURATION
# ============================================================================
# Settings for document-to-markdown conversion services

# EXTRACTION_SERVICE_TIMEOUT: Timeout in seconds for extraction API calls
#   - Default: 180 seconds (3 minutes)
#   - With retries: 180s → 210s → 240s (progressive timeout extension)
#   - Large PDFs or OCR-heavy documents may need longer timeouts
EXTRACTION_SERVICE_TIMEOUT=180

# DOCLING_TIMEOUT: Timeout in seconds for Docling service API calls
#   - Default: 300 seconds (5 minutes)
#   - Docling processes complex layouts and may take longer than basic extraction
DOCLING_TIMEOUT=300

# DOCLING_SERVE_MAX_SYNC_WAIT: Maximum wait time for Docling synchronous operations
#   - Only applicable when using Docling service
DOCLING_SERVE_MAX_SYNC_WAIT=300


# ============================================================================
# PUBLIC SERVICE URLS (Frontend)
# ============================================================================
# Public-facing URLs for browser access to service documentation
# These map internal Docker service names to localhost URLs

# NEXT_PUBLIC_API_URL: Public URL for backend API
#   - Used by frontend to access backend services
#   - Default: http://localhost:8000 (matches docker-compose port mapping 8000:8000)
NEXT_PUBLIC_API_URL=http://localhost:8000

# NEXT_PUBLIC_EXTRACTION_URL: Public URL for extraction service
#   - Used by frontend health page to link to extraction service docs
#   - Default: http://localhost:8010 (matches docker-compose port mapping 8010:8010)
NEXT_PUBLIC_EXTRACTION_URL=http://localhost:8010

# NEXT_PUBLIC_DOCLING_URL: Public URL for Docling service
#   - Used by frontend health page to link to Docling service docs
#   - Default: http://localhost:5151 (matches docker-compose port mapping 5151:5001)
#   - Note: External port 5151 maps to internal port 5001
NEXT_PUBLIC_DOCLING_URL=http://localhost:5151

# NEXT_PUBLIC_REDIS_URL: Public URL for Redis (if exposing management UI)
#   - Default: http://localhost:6379 (matches docker-compose port mapping 6379:6379)
#   - Typically not used unless running a Redis management UI
NEXT_PUBLIC_REDIS_URL=http://localhost:6379


# ============================================================================
# LOCAL SCRIPT CONFIGURATION
# ============================================================================
# Used by SharePoint automation scripts when running on the host.

# CURATORE_API_URL: Base URL for Curatore API (defaults to NEXT_PUBLIC_API_URL)
CURATORE_API_URL=http://localhost:8000


# ============================================================================
# EXTRACTION ENGINE CONFIGURATION
# ============================================================================

# ENABLE_DOCLING_SERVICE: Start Docling service container
#   - true: Start Docling container (requires more resources)
#   - false: Disable Docling (extraction-service only)
#   - Used by docker-compose profiles
ENABLE_DOCLING_SERVICE=false

# EXTRACTION_ENGINES: Space or comma-separated list of engines to start
#   - "default": Internal extraction-service (always runs)
#   - "docling": Docling Serve (requires ENABLE_DOCLING_SERVICE=true)
#   - Example: "default docling" enables both
#   - Note: "default" always runs; this setting adds additional engines
EXTRACTION_ENGINES="default"

# EXTRACTION_PRIORITY: Active extraction engine selection
#   Options:
#     - auto: Intelligent selection (prefers Docling if available, falls back to default)
#             Best for: Production with both services enabled
#             Behavior: Docling (3 retries) → extraction-service (3 retries)
#
#     - default: Use extraction-service (internal microservice)
#             Best for: Standard deployments, lighter resource usage
#             Behavior: extraction-service (3 retries) → Docling failover if enabled
#             Features: Fast, handles most documents, OCR support
#
#     - docling: Use Docling Serve (external service)
#             Best for: Complex PDFs, Office docs with rich layouts
#             Behavior: Docling (3 retries) → extraction-service failover if enabled
#             Features: Advanced layout analysis, table extraction, formula support
#
#     - none: Disable extraction (returns placeholder text)
#             Best for: Testing or markdown-only workflows
#
#   Retry Logic (applies to all engines):
#     - Each engine attempts extraction up to 3 times
#     - Timeouts increase by 30s per retry (180s → 210s → 240s)
#     - On total failure, failover to alternate engine (if available)
#     - Example with auto: Up to 6 total attempts (3 Docling + 3 extraction-service)
EXTRACTION_PRIORITY=default


# ============================================================================
# SHAREPOINT / MICROSOFT GRAPH CONFIGURATION
# ============================================================================
# Used by scripts that connect to SharePoint via Microsoft Graph.

# MS_TENANT_ID: Azure AD tenant ID (GUID)
MS_TENANT_ID=

# MS_CLIENT_ID: Azure AD app registration client ID
MS_CLIENT_ID=

# MS_CLIENT_SECRET: Azure AD app registration client secret
MS_CLIENT_SECRET=

# MS_GRAPH_SCOPE: OAuth scope for app-only access
#   - Default: https://graph.microsoft.com/.default
MS_GRAPH_SCOPE=https://graph.microsoft.com/.default

# MS_GRAPH_BASE_URL: Microsoft Graph API base URL
#   - Default: https://graph.microsoft.com/v1.0
MS_GRAPH_BASE_URL=https://graph.microsoft.com/v1.0


# ============================================================================
# DATABASE CONFIGURATION
# ============================================================================
# Multi-tenant persistence layer for organizations, users, connections, and settings

# DATABASE_URL: SQLAlchemy database connection URL
#   SQLite (development):
#     - sqlite+aiosqlite:///./data/curatore.db
#     - File-based, zero configuration, good for single-node deployments
#   PostgreSQL (production):
#     - postgresql+asyncpg://user:password@localhost:5432/curatore
#     - Recommended for production, multi-worker support, better concurrency
#   Default: SQLite
DATABASE_URL=sqlite+aiosqlite:///./data/curatore.db

# DB_POOL_SIZE: Database connection pool size (PostgreSQL only)
#   - Default: 20 connections
#   - Increase for high-traffic deployments
DB_POOL_SIZE=20

# DB_MAX_OVERFLOW: Maximum overflow connections (PostgreSQL only)
#   - Default: 40 additional connections beyond pool_size
#   - Total max connections = pool_size + max_overflow
DB_MAX_OVERFLOW=40

# DB_POOL_RECYCLE: Connection recycle time in seconds (PostgreSQL only)
#   - Default: 3600 (1 hour)
#   - Connections are recycled after this time to prevent stale connections
DB_POOL_RECYCLE=3600


# ============================================================================
# AUTHENTICATION & SECURITY
# ============================================================================
# JWT token authentication and API key management

# JWT_SECRET_KEY: Secret key for signing JWT tokens
#   - CRITICAL: Change this in production!
#   - Generate with: openssl rand -hex 32
#   - Keep this secret and never commit to version control
JWT_SECRET_KEY=your-secret-key-change-in-production

# JWT_ALGORITHM: Algorithm for JWT token signing
#   - Default: HS256 (HMAC with SHA-256)
#   - Other options: HS384, HS512, RS256 (requires RSA keys)
JWT_ALGORITHM=HS256

# JWT_ACCESS_TOKEN_EXPIRE_MINUTES: Access token expiration in minutes
#   - Default: 60 minutes (1 hour)
#   - Shorter = more secure but more frequent refreshes
#   - Longer = better UX but wider attack window
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=60

# JWT_REFRESH_TOKEN_EXPIRE_DAYS: Refresh token expiration in days
#   - Default: 30 days
#   - Used to obtain new access tokens without re-login
JWT_REFRESH_TOKEN_EXPIRE_DAYS=30

# BCRYPT_ROUNDS: Bcrypt hashing work factor
#   - Default: 12 rounds
#   - Higher = more secure but slower
#   - Lower = faster but less secure
#   - Recommended: 12-14 for production
BCRYPT_ROUNDS=12

# API_KEY_PREFIX: Prefix for API keys
#   - Default: "cur_"
#   - Used for display purposes (e.g., cur_1234abcd...)
API_KEY_PREFIX=cur_


# ============================================================================
# EMAIL CONFIGURATION
# ============================================================================
# Email delivery for user notifications (verification, password reset, etc.)

# EMAIL_BACKEND: Email backend to use
#   Options:
#     - console: Log emails to console (development/testing)
#     - smtp: Send via SMTP server (production)
#     - sendgrid: Send via SendGrid API (requires sendgrid Python package)
#     - ses: Send via AWS Simple Email Service (requires boto3 Python package)
#   Default: console
EMAIL_BACKEND=console

# EMAIL_FROM_ADDRESS: From email address for outgoing emails
#   - Used as sender address
#   - Should be a verified domain in production
EMAIL_FROM_ADDRESS=noreply@curatore.app

# EMAIL_FROM_NAME: From name for outgoing emails
#   - Displayed as sender name
EMAIL_FROM_NAME=Curatore

# FRONTEND_BASE_URL: Frontend base URL for email links
#   - Used to generate verification and password reset links
#   - Should match your frontend deployment URL
FRONTEND_BASE_URL=http://localhost:3000

# -----------------------------------------------------------------------------
# SMTP Configuration (if EMAIL_BACKEND=smtp)
# -----------------------------------------------------------------------------

# SMTP_HOST: SMTP server hostname
#   Examples:
#     - Gmail: smtp.gmail.com
#     - Outlook: smtp.office365.com
#     - SendGrid: smtp.sendgrid.net
SMTP_HOST=

# SMTP_PORT: SMTP server port
#   - 587: TLS/STARTTLS (recommended)
#   - 465: SSL
#   - 25: Unencrypted (not recommended)
SMTP_PORT=587

# SMTP_USERNAME: SMTP authentication username
#   - Usually your email address
SMTP_USERNAME=

# SMTP_PASSWORD: SMTP authentication password
#   - For Gmail: Use app-specific password, not your regular password
#   - Keep this secret and never commit to version control
SMTP_PASSWORD=

# SMTP_USE_TLS: Use TLS encryption
#   - true: Use TLS (recommended for port 587)
#   - false: No TLS (only use for port 465 with SSL)
SMTP_USE_TLS=true

# -----------------------------------------------------------------------------
# SendGrid Configuration (if EMAIL_BACKEND=sendgrid)
# -----------------------------------------------------------------------------

# SENDGRID_API_KEY: SendGrid API key
#   - Get from: https://app.sendgrid.com/settings/api_keys
#   - Keep this secret and never commit to version control
SENDGRID_API_KEY=

# -----------------------------------------------------------------------------
# AWS SES Configuration (if EMAIL_BACKEND=ses)
# -----------------------------------------------------------------------------

# AWS_REGION: AWS region for SES
#   - Example: us-east-1, us-west-2, eu-west-1
AWS_REGION=us-east-1

# AWS_ACCESS_KEY_ID: AWS access key ID
#   - Optional: If not provided, uses IAM role or default credentials
AWS_ACCESS_KEY_ID=

# AWS_SECRET_ACCESS_KEY: AWS secret access key
#   - Optional: If not provided, uses IAM role or default credentials
#   - Keep this secret and never commit to version control
AWS_SECRET_ACCESS_KEY=

# -----------------------------------------------------------------------------
# Token Expiration Settings
# -----------------------------------------------------------------------------

# EMAIL_VERIFICATION_TOKEN_EXPIRE_HOURS: Email verification token expiration
#   - Default: 24 hours
#   - How long verification links remain valid
EMAIL_VERIFICATION_TOKEN_EXPIRE_HOURS=24

# PASSWORD_RESET_TOKEN_EXPIRE_HOURS: Password reset token expiration
#   - Default: 1 hour
#   - How long password reset links remain valid
#   - Keep short for security
PASSWORD_RESET_TOKEN_EXPIRE_HOURS=1

# EMAIL_VERIFICATION_GRACE_PERIOD_DAYS: Grace period before enforcing verification
#   - Default: 7 days
#   - Users can access the app for this many days without verifying email
#   - After grace period, email verification is required
EMAIL_VERIFICATION_GRACE_PERIOD_DAYS=7


# ============================================================================
# MULTI-TENANCY & ORGANIZATIONS
# ============================================================================
# Organization-based multi-tenancy settings

# ENABLE_AUTH: Enable authentication layer
#   - true: Require JWT or API key authentication for all endpoints
#   - false: Allow unauthenticated access (backward compatibility mode)
#   - Default: false (for backward compatibility with ENV-based config)
#   - Set to true after running seed command and creating initial admin user
ENABLE_AUTH=false

# DEFAULT_ORG_ID: Default organization ID for unauthenticated requests
#   - Only used when ENABLE_AUTH=false
#   - Set to UUID of default organization (created by seed command)
#   - Leave empty to use first organization in database
DEFAULT_ORG_ID=

# AUTO_TEST_CONNECTIONS: Automatically test connections on save
#   - true: Run health check when creating/updating connections
#   - false: Skip automatic testing (test manually via API)
#   - Default: true
#   - Provides immediate feedback on connection validity
AUTO_TEST_CONNECTIONS=true


# ============================================================================
# INITIAL SEEDING (First-time Setup)
# ============================================================================
# Used by seed command to create initial organization and admin user
# Run: python -m app.commands.seed --create-admin

# ADMIN_EMAIL: Initial admin user email
#   - Used for first login
#   - Change after first login recommended
ADMIN_EMAIL=admin@example.com

# ADMIN_USERNAME: Initial admin username
#   - Used for first login
ADMIN_USERNAME=admin

# ADMIN_PASSWORD: Initial admin password
#   - CRITICAL: Change immediately after first login!
#   - Never use default password in production
ADMIN_PASSWORD=changeme

# ADMIN_FULL_NAME: Initial admin full name
ADMIN_FULL_NAME=Admin User

# DEFAULT_ORG_NAME: Default organization name
#   - Created during initial seed
DEFAULT_ORG_NAME=Default Organization

# DEFAULT_ORG_SLUG: Default organization URL slug
#   - Used in URLs and identifiers
#   - Must be URL-safe (lowercase, no spaces)
DEFAULT_ORG_SLUG=default
