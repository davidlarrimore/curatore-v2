# ============================================================================
# Curatore v2 - Service Configuration
# ============================================================================
# Copy this file to config.yml and customize for your environment.
#
# Environment Variable References:
#   Use ${VAR_NAME} to reference environment variables from .env
#   Example: api_key: ${OPENAI_API_KEY}
#
# Optional Settings:
#   Settings marked with "(optional)" have sensible defaults
#   and can be omitted if defaults are acceptable.
#
# Configuration Priority:
#   1. config.yml (if present)
#   2. Environment variables from .env
#   3. Built-in defaults
# ============================================================================

version: "2.0"

# ============================================================================
# LLM Configuration (optional)
# ============================================================================
# Language model for document quality evaluation
#
# Supports: OpenAI, Ollama, OpenWebUI, LM Studio, and compatible endpoints
# If not configured here, falls back to OPENAI_* environment variables

llm:
  # Provider name (openai, ollama, openwebui, lmstudio)
  provider: openai

  # API key or authentication token
  # Recommended: Reference from environment for security
  api_key: ${OPENAI_API_KEY}

  # API endpoint URL
  # Examples:
  #   - OpenAI: https://api.openai.com/v1
  #   - Ollama: http://localhost:11434/v1
  #   - OpenWebUI: http://localhost:3000/v1
  #   - LM Studio: http://localhost:1234/v1
  base_url: https://api.openai.com/v1

  # Model identifier
  # Examples:
  #   - OpenAI: gpt-4o-mini, gpt-4o, gpt-4-turbo
  #   - Ollama: llama3, mistral, mixtral
  model: gpt-4o-mini

  # Request timeout in seconds (optional, default: 60)
  # Increase for slower models or large documents
  timeout: 60

  # Maximum retry attempts (optional, default: 3)
  max_retries: 3

  # Generation temperature (optional, default: 0.7)
  # Range: 0.0 (deterministic) to 2.0 (creative)
  temperature: 0.7

  # Verify SSL certificates (optional, default: true)
  # Set to false for self-signed certificates in development
  verify_ssl: true

  # Provider-specific options (optional)
  # Pass additional parameters to the LLM provider
  options:
    max_tokens: 4096
    top_p: 1.0


# ============================================================================
# Extraction Engine Configuration (optional)
# ============================================================================
# Document-to-markdown conversion engines
#
# Curatore supports multiple extraction engines for document conversion.
# Enable/disable engines as needed for your use case.
#
# Available engines:
#   - extraction-service: Internal service using MarkItDown + Tesseract OCR
#   - docling: IBM Docling for complex PDFs and Office documents
#   - tika: Apache Tika (coming soon)
#
# If not configured here, falls back to EXTRACTION_* environment variables

extraction:
  # Default engine to use when none specified (optional, default: extraction-service)
  # IMPORTANT: This must match the 'name' field of one of the enabled engines below
  # Options: extraction-service, docling, tika
  default_engine: extraction-service

  # List of available extraction engines
  # Users can select these when creating jobs via Connections UI
  engines:
    # -------------------------------------------------------------------------
    # Internal Extraction Service (Recommended)
    # -------------------------------------------------------------------------
    # Built-in service using MarkItDown + Tesseract OCR
    # Best for: General documents, PDFs, Office files, images with text
    # API Endpoint: /api/v1/extract (automatically used based on engine_type)
    - name: extraction-service
      display_name: "Internal Extraction Service"
      description: "Built-in extraction using MarkItDown and Tesseract OCR"

      # Engine type identifier (required)
      # This determines which extraction logic and API endpoint to use
      # API endpoints are predefined per engine_type and cannot be overridden
      engine_type: extraction-service

      # Service base URL (required)
      service_url: http://extraction:8010

      # Request timeout in seconds (optional, default: 300)
      timeout: 300

      # Enable this engine (required)
      # Set to false to disable without removing configuration
      enabled: true

      # Verify SSL certificates (optional, default: true)
      verify_ssl: true

      # Docling OCR toggle (optional, default: true)
      # When set, this maps to Docling's enable_ocr option.
      docling_ocr_enabled: true

      # OCR settings (Tesseract-specific, optional)
      # These settings apply to the extraction-service's OCR processing
      ocr:
        # Tesseract OCR language code (optional, default: eng)
        # Examples: eng, spa, fra, deu, or combinations like "eng+spa"
        # See: https://github.com/tesseract-ocr/tesseract/blob/main/doc/tesseract.1.asc#languages
        language: eng

        # Page Segmentation Mode (optional, default: 3)
        # 3 = Fully automatic page segmentation (recommended)
        # 6 = Uniform block of text
        # 11 = Sparse text (find as much text as possible)
        # See: https://github.com/tesseract-ocr/tesseract/blob/main/doc/tesseract.1.asc#options
        psm: 3

    # -------------------------------------------------------------------------
    # Docling (IBM Research)
    # -------------------------------------------------------------------------
    # Advanced extraction engine for complex PDFs and Office documents
    # Best for: Academic papers, technical documents, complex layouts
    # Requires: Docling service running (see docker-compose.yml)
    # API Endpoint: /v1/convert/file (automatically used based on engine_type)
    - name: docling
      display_name: "Docling (IBM Research)"
      description: "Advanced extraction for complex PDFs and Office documents"

      # Engine type identifier (required)
      # This determines which extraction logic and API endpoint to use
      # API endpoints are predefined per engine_type and cannot be overridden
      engine_type: docling

      # Docling service URL (required)
      # Note: Docling typically runs on port 5001
      service_url: http://docling:5001

      # Request timeout in seconds (optional, default: 600)
      # Docling can be slower for complex documents
      timeout: 600

      # Enable this engine (required)
      # Set to true to enable Docling extraction
      # Requires: ENABLE_DOCLING_SERVICE=true in docker-compose
      enabled: false

      # Verify SSL certificates (optional, default: true)
      verify_ssl: true

      # Docling-specific options (optional)
      # These are passed as query parameters to Docling's /v1/convert/file endpoint
      # See: https://deepwiki.com/docling-project/docling-serve/4.1-conversion-endpoints
      options:
        # Output format (required, default: markdown)
        output_format: markdown

        # Image export mode (optional, default: placeholder)
        # Options: placeholder, embedded, none
        image_export_mode: placeholder

        # Pipeline type (optional, default: standard)
        # Options: standard, fast, accurate
        pipeline_type: standard

        # Enable OCR for scanned documents (optional, default: true)
        enable_ocr: true

        # OCR engine (optional, default: auto)
        # Options: auto, tesseract, easyocr
        ocr_engine: auto

        # Table extraction mode (optional, default: accurate)
        # Options: accurate, fast, none
        table_mode: accurate

    # -------------------------------------------------------------------------
    # Apache Tika (Coming Soon)
    # -------------------------------------------------------------------------
    # Popular open-source content analysis toolkit
    # Best for: Wide format support, metadata extraction
    # Status: Not yet implemented - configuration shown for reference
    # - name: tika
    #   display_name: "Apache Tika"
    #   description: "Open-source content analysis and extraction"
    #   engine_type: tika
    #   service_url: http://tika:9998
    #   endpoint_path: /tika
    #   timeout: 300
    #   enabled: false
    #   verify_ssl: true


# ============================================================================
# Microsoft SharePoint Configuration (optional)
# ============================================================================
# Microsoft Graph API integration for SharePoint document retrieval
#
# Requires:
#   - Azure AD app registration with client credentials
#   - Microsoft Graph API permissions: Sites.Read.All or Files.Read.All
#   - Admin consent granted for the application
#
# If not configured here, falls back to MS_* environment variables

sharepoint:
  # Enable SharePoint integration (optional, default: true)
  enabled: true

  # Azure AD tenant ID (GUID format)
  # Recommended: Reference from environment for security
  tenant_id: ${MS_TENANT_ID}

  # Azure AD app registration client ID
  client_id: ${MS_CLIENT_ID}

  # Azure AD app registration client secret
  # CRITICAL: Keep this secret! Reference from environment.
  client_secret: ${MS_CLIENT_SECRET}

  # OAuth scope (optional, default: https://graph.microsoft.com/.default)
  graph_scope: https://graph.microsoft.com/.default

  # Microsoft Graph API base URL (optional)
  graph_base_url: https://graph.microsoft.com/v1.0

  # Request timeout in seconds (optional, default: 60)
  timeout: 60

  # Maximum retry attempts (optional, default: 3)
  max_retries: 3


# ============================================================================
# Email Service Configuration (optional)
# ============================================================================
# Email delivery for user notifications (verification, password reset, etc.)
#
# Supported backends:
#   - console: Log emails to console (development/testing)
#   - smtp: Send via SMTP server (production)
#   - sendgrid: Send via SendGrid API
#   - ses: Send via AWS Simple Email Service
#
# If not configured here, falls back to EMAIL_* environment variables

email:
  # Email backend (console, smtp, sendgrid, ses)
  backend: console  # Change to 'smtp' for production

  # From email address
  # Should be a verified domain in production
  from_address: noreply@curatore.app

  # From display name
  from_name: Curatore

  # -----------------------------------------------------------------------------
  # SMTP Configuration (required if backend=smtp)
  # -----------------------------------------------------------------------------
  smtp:
    # SMTP server hostname
    # Examples:
    #   - Gmail: smtp.gmail.com
    #   - Outlook: smtp.office365.com
    #   - SendGrid: smtp.sendgrid.net
    host: ${SMTP_HOST}

    # SMTP server port (optional, default: 587)
    # - 587: TLS/STARTTLS (recommended)
    # - 465: SSL
    # - 25: Unencrypted (not recommended)
    port: 587

    # SMTP authentication username (optional)
    # Usually your email address
    username: ${SMTP_USERNAME}

    # SMTP authentication password (optional)
    # For Gmail: Use app-specific password, not your regular password
    # CRITICAL: Keep this secret! Reference from environment.
    password: ${SMTP_PASSWORD}

    # Use TLS encryption (optional, default: true)
    use_tls: true

    # Connection timeout in seconds (optional, default: 30)
    timeout: 30

  # -----------------------------------------------------------------------------
  # SendGrid Configuration (required if backend=sendgrid)
  # -----------------------------------------------------------------------------
  # sendgrid:
  #   api_key: ${SENDGRID_API_KEY}

  # -----------------------------------------------------------------------------
  # AWS SES Configuration (required if backend=ses)
  # -----------------------------------------------------------------------------
  # aws_ses:
  #   region: us-east-1
  #   access_key_id: ${AWS_ACCESS_KEY_ID}  # Optional, uses IAM role if not provided
  #   secret_access_key: ${AWS_SECRET_ACCESS_KEY}  # Optional


# ============================================================================
# Storage Configuration (optional)
# ============================================================================
# File storage management settings with defaults

storage:
  # Use hierarchical organization-based file structure (optional, default: true)
  # - true: organizations/{org_id}/batches|adhoc structure
  # - false: Flat uploaded_files/ and processed_files/ structure
  hierarchical: true

  # File deduplication settings
  deduplication:
    # Enable duplicate file detection (optional, default: true)
    enabled: true

    # Deduplication strategy (optional, default: symlink)
    # - symlink: Create symbolic links (recommended, space efficient)
    # - copy: Copy files from dedupe storage (compatible, uses more space)
    # - reference: Store only reference (most efficient, requires lookup)
    strategy: symlink

    # Hash algorithm (optional, default: sha256)
    # Options: md5, sha1, sha256, sha512
    hash_algorithm: sha256

    # Minimum file size to deduplicate in bytes (optional, default: 1024)
    # Files smaller than this are not deduplicated (overhead not worth it)
    min_file_size: 1024

  # File retention policies (days/hours)
  retention:
    # Days to retain uploaded files (optional, default: 7)
    uploaded_days: 7

    # Days to retain processed markdown files (optional, default: 30)
    processed_days: 30

    # Days to retain batch files and metadata (optional, default: 14)
    batch_days: 14

    # Hours to retain temporary processing files (optional, default: 24)
    temp_hours: 24

  # Automatic cleanup settings
  cleanup:
    # Enable automatic file cleanup (optional, default: true)
    enabled: true

    # Cleanup schedule in cron format (optional, default: "0 2 * * *")
    # Format: "minute hour day month day_of_week"
    # Examples:
    #   - "0 2 * * *": Daily at 2 AM
    #   - "0 */6 * * *": Every 6 hours
    #   - "0 0 * * 0": Weekly on Sunday at midnight
    schedule_cron: "0 2 * * *"

    # Files to process per cleanup batch (optional, default: 1000)
    # Higher = faster cleanup but more memory usage
    batch_size: 1000

    # Run cleanup in dry-run mode (optional, default: false)
    # - true: Log what would be deleted without actually deleting
    # - false: Actually delete expired files
    dry_run: false


# ============================================================================
# Queue Configuration (optional)
# ============================================================================
# Celery background job processing settings

queue:
  # Redis URL for task queue broker (optional, default: redis://redis:6379/0)
  broker_url: redis://redis:6379/0

  # Redis URL for storing task results (optional, default: redis://redis:6379/1)
  result_backend: redis://redis:6379/1

  # Default queue name (optional, default: processing)
  default_queue: processing

  # Worker concurrency level (optional, default: 4)
  # Number of worker processes per container
  worker_concurrency: 4

  # Task timeout in seconds (optional, default: 3600)
  # Maximum time a task can run before being terminated
  task_timeout: 3600
