# ============================================================================
# Curatore v2 - Service Configuration
# ============================================================================
# Copy this file to config.yml and customize for your environment.
#
# Environment Variable References:
#   Use ${VAR_NAME} to reference environment variables from .env
#   Example: api_key: ${OPENAI_API_KEY}
#
# Optional Settings:
#   Settings marked with "(optional)" have sensible defaults
#   and can be omitted if defaults are acceptable.
#
# Configuration Priority:
#   1. config.yml (if present)
#   2. Environment variables from .env
#   3. Built-in defaults
# ============================================================================

version: "2.0"

# ============================================================================
# LLM Configuration (optional)
# ============================================================================
# Language model for document quality evaluation
#
# Supports: OpenAI, Ollama, OpenWebUI, LM Studio, and compatible endpoints
# If not configured here, falls back to OPENAI_* environment variables

llm:
  # Provider name (openai, ollama, openwebui, lmstudio)
  provider: openai

  # API key or authentication token
  # Recommended: Reference from environment for security
  api_key: ${OPENAI_API_KEY}

  # API endpoint URL
  # Examples:
  #   - OpenAI: https://api.openai.com/v1
  #   - Ollama: http://localhost:11434/v1
  #   - OpenWebUI: http://localhost:3000/v1
  #   - LM Studio: http://localhost:1234/v1
  base_url: https://api.openai.com/v1

  # Model identifier
  # Examples:
  #   - OpenAI: gpt-4o-mini, gpt-4o, gpt-4-turbo
  #   - Ollama: llama3, mistral, mixtral
  model: gpt-4o-mini

  # Request timeout in seconds (optional, default: 60)
  # Increase for slower models or large documents
  timeout: 60

  # Maximum retry attempts (optional, default: 3)
  max_retries: 3

  # Generation temperature (optional, default: 0.7)
  # Range: 0.0 (deterministic) to 2.0 (creative)
  temperature: 0.7

  # Verify SSL certificates (optional, default: true)
  # Set to false for self-signed certificates in development
  verify_ssl: true

  # Provider-specific options (optional)
  # Pass additional parameters to the LLM provider
  options:
    max_tokens: 4096
    top_p: 1.0


# ============================================================================
# Extraction Engine Configuration (optional)
# ============================================================================
# Document-to-markdown conversion engines
#
# Curatore supports multiple extraction engines for document conversion.
# Enable/disable engines as needed for your use case.
#
# Available engines:
#   - extraction-service: Internal service using MarkItDown + Tesseract OCR
#   - docling: IBM Docling for complex PDFs and Office documents
#   - tika: Apache Tika for wide format support (1000+ types)
#
# If not configured here, falls back to EXTRACTION_* environment variables

extraction:
  # Default engine to use when none specified (optional, default: extraction-service)
  # IMPORTANT: This must match the 'name' field of one of the enabled engines below
  # Options: extraction-service, docling, tika
  default_engine: extraction-service

  # List of available extraction engines
  # Users can select these when creating jobs via Connections UI
  engines:
    # -------------------------------------------------------------------------
    # Internal Extraction Service (Recommended)
    # -------------------------------------------------------------------------
    # Built-in service using MarkItDown + Tesseract OCR
    # Best for: General documents, PDFs, Office files, images with text
    # API Endpoint: /api/v1/extract (automatically used based on engine_type)
    - name: extraction-service
      display_name: "Internal Extraction Service"
      description: "Built-in extraction using MarkItDown and Tesseract OCR"

      # Engine type identifier (required)
      # This determines which extraction logic and API endpoint to use
      # API endpoints are predefined per engine_type and cannot be overridden
      engine_type: extraction-service

      # Service base URL (required)
      service_url: http://extraction:8010

      # Request timeout in seconds (optional, default: 300)
      timeout: 300

      # Enable this engine (required)
      # Set to false to disable without removing configuration
      enabled: true

      # Verify SSL certificates (optional, default: true)
      verify_ssl: true

      # Docling OCR toggle (optional, default: true)
      # When set, this maps to Docling's enable_ocr option.
      docling_ocr_enabled: true

      # OCR settings (Tesseract-specific, optional)
      # These settings apply to the extraction-service's OCR processing
      ocr:
        # Tesseract OCR language code (optional, default: eng)
        # Examples: eng, spa, fra, deu, or combinations like "eng+spa"
        # See: https://github.com/tesseract-ocr/tesseract/blob/main/doc/tesseract.1.asc#languages
        language: eng

        # Page Segmentation Mode (optional, default: 3)
        # 3 = Fully automatic page segmentation (recommended)
        # 6 = Uniform block of text
        # 11 = Sparse text (find as much text as possible)
        # See: https://github.com/tesseract-ocr/tesseract/blob/main/doc/tesseract.1.asc#options
        psm: 3

    # -------------------------------------------------------------------------
    # Docling (IBM Research)
    # -------------------------------------------------------------------------
    # Advanced extraction engine for complex PDFs and Office documents
    # Best for: Academic papers, technical documents, complex layouts
    # Requires: Docling service running (see docker-compose.yml)
    # API Endpoint: /v1/convert/file (automatically used based on engine_type)
    - name: docling
      display_name: "Docling (IBM Research)"
      description: "Advanced extraction for complex PDFs and Office documents"

      # Engine type identifier (required)
      # This determines which extraction logic and API endpoint to use
      # API endpoints are predefined per engine_type and cannot be overridden
      engine_type: docling

      # Docling service URL (required)
      # Note: Docling typically runs on port 5001
      service_url: http://docling:5001

      # Request timeout in seconds (optional, default: 600)
      # Docling can be slower for complex documents
      timeout: 600

      # Enable this engine (required)
      # Set to true to enable Docling extraction
      # Requires: ENABLE_DOCLING_SERVICE=true in docker-compose
      enabled: false

      # Verify SSL certificates (optional, default: true)
      verify_ssl: true

      # Docling-specific options (optional)
      # These are passed as query parameters to Docling's /v1/convert/file endpoint
      # See: https://deepwiki.com/docling-project/docling-serve/4.1-conversion-endpoints
      options:
        # Output format (required, default: markdown)
        output_format: markdown

        # Image export mode (optional, default: placeholder)
        # Options: placeholder, embedded, none
        image_export_mode: placeholder

        # Pipeline type (optional, default: standard)
        # Options: standard, fast, accurate
        pipeline_type: standard

        # Enable OCR for scanned documents (optional, default: true)
        enable_ocr: true

        # OCR engine (optional, default: auto)
        # Options: auto, tesseract, easyocr
        ocr_engine: auto

        # Table extraction mode (optional, default: accurate)
        # Options: accurate, fast, none
        table_mode: accurate

    # -------------------------------------------------------------------------
    # Apache Tika
    # -------------------------------------------------------------------------
    # Popular open-source content analysis toolkit from Apache Software Foundation
    # Best for: Wide format support (1000+ types), metadata extraction, archives
    # Requires: Tika Server running (see docker-compose.yml)
    # API Endpoint: /tika (automatically used based on engine_type)
    # Reference: https://cwiki.apache.org/confluence/display/TIKA/TikaServer
    - name: tika
      display_name: "Apache Tika"
      description: "Wide format support (1000+ types) with metadata extraction"

      # Engine type identifier (required)
      # This determines which extraction logic and API endpoint to use
      engine_type: tika

      # Tika Server URL (required)
      # Default port is 9998
      service_url: http://tika:9998

      # Request timeout in seconds (optional, default: 300)
      timeout: 300

      # Enable this engine (required)
      # Set to true to enable Tika extraction
      enabled: false

      # Verify SSL certificates (optional, default: true)
      verify_ssl: true

      # Tika-specific options (optional)
      options:
        # Output format preference (optional, default: markdown)
        # Options:
        #   - markdown: HTML converted to Markdown (recommended for RAG)
        #   - html: Raw HTML output
        #   - text: Plain text output
        accept_format: markdown

        # Extract document metadata (optional, default: true)
        # Extracts author, title, creation date, etc.
        extract_metadata: true

        # OCR strategy for images/scanned PDFs (optional)
        # Options:
        #   - no_ocr: Skip OCR entirely
        #   - ocr_only: Only use OCR (ignore embedded text)
        #   - ocr_and_text: Use both OCR and embedded text
        # ocr_strategy: ocr_and_text

        # OCR language for Tesseract (optional, default: eng)
        # Examples: eng, spa, fra, deu, or combinations like "eng+spa"
        ocr_language: eng

        # PDF OCR strategy (optional)
        # Controls how PDFs with images are processed
        # pdf_strategy: ocr_and_text


# ============================================================================
# Playwright Rendering Service Configuration (optional)
# ============================================================================
# Browser-based rendering service for JavaScript-heavy web scraping.
# Required for crawling Single Page Applications (SPAs) and dynamic content.
#
# The Playwright service renders pages with a real browser, executes JavaScript,
# and extracts content inline during crawl (no separate extraction job needed).
#
# If not configured here, falls back to PLAYWRIGHT_* environment variables

playwright:
  # Enable Playwright rendering service (optional, default: true if URL provided)
  enabled: true

  # Playwright service URL (required to enable)
  # Examples:
  #   - Docker: http://playwright:8011
  #   - Local: http://localhost:8011
  service_url: http://playwright:8011

  # Request timeout in seconds (optional, default: 60)
  # Total time allowed for page render + content extraction
  timeout: 60

  # Maximum retry attempts for failed requests (optional, default: 3)
  max_retries: 3

  # Browser pool size (optional, default: 3)
  # Number of browser instances to maintain
  browser_pool_size: 3

  # Default viewport dimensions (optional)
  default_viewport_width: 1920
  default_viewport_height: 1080

  # Default page load timeout in ms (optional, default: 30000)
  default_timeout_ms: 30000

  # Default wait for selector timeout in ms (optional, default: 5000)
  default_wait_timeout_ms: 5000

  # File extensions to identify as downloadable documents (optional)
  # When crawling web pages, links to these file types will be extracted
  document_extensions:
    - ".pdf"
    - ".docx"
    - ".doc"
    - ".xlsx"
    - ".xls"
    - ".pptx"
    - ".ppt"


# ============================================================================
# Microsoft SharePoint Configuration (optional)
# ============================================================================
# Microsoft Graph API integration for SharePoint document retrieval
#
# Requires:
#   - Azure AD app registration with client credentials
#   - Microsoft Graph API permissions: Sites.Read.All or Files.Read.All
#   - Admin consent granted for the application
#
# If not configured here, falls back to MS_* environment variables

sharepoint:
  # Enable SharePoint integration (optional, default: true)
  enabled: true

  # Azure AD tenant ID (GUID format)
  # Recommended: Reference from environment for security
  tenant_id: ${MS_TENANT_ID}

  # Azure AD app registration client ID
  client_id: ${MS_CLIENT_ID}

  # Azure AD app registration client secret
  # CRITICAL: Keep this secret! Reference from environment.
  client_secret: ${MS_CLIENT_SECRET}

  # OAuth scope (optional, default: https://graph.microsoft.com/.default)
  graph_scope: https://graph.microsoft.com/.default

  # Microsoft Graph API base URL (optional)
  graph_base_url: https://graph.microsoft.com/v1.0

  # Request timeout in seconds (optional, default: 60)
  timeout: 60

  # Maximum retry attempts (optional, default: 3)
  max_retries: 3


# ============================================================================
# Email Service Configuration (optional)
# ============================================================================
# Email delivery for user notifications (verification, password reset, etc.)
#
# Supported backends:
#   - console: Log emails to console (development/testing)
#   - smtp: Send via SMTP server (production)
#   - sendgrid: Send via SendGrid API
#   - ses: Send via AWS Simple Email Service
#
# If not configured here, falls back to EMAIL_* environment variables

email:
  # Email backend (console, smtp, sendgrid, ses)
  backend: console  # Change to 'smtp' for production

  # From email address
  # Should be a verified domain in production
  from_address: noreply@curatore.app

  # From display name
  from_name: Curatore

  # -----------------------------------------------------------------------------
  # SMTP Configuration (required if backend=smtp)
  # -----------------------------------------------------------------------------
  smtp:
    # SMTP server hostname
    # Examples:
    #   - Gmail: smtp.gmail.com
    #   - Outlook: smtp.office365.com
    #   - SendGrid: smtp.sendgrid.net
    host: ${SMTP_HOST}

    # SMTP server port (optional, default: 587)
    # - 587: TLS/STARTTLS (recommended)
    # - 465: SSL
    # - 25: Unencrypted (not recommended)
    port: 587

    # SMTP authentication username (optional)
    # Usually your email address
    username: ${SMTP_USERNAME}

    # SMTP authentication password (optional)
    # For Gmail: Use app-specific password, not your regular password
    # CRITICAL: Keep this secret! Reference from environment.
    password: ${SMTP_PASSWORD}

    # Use TLS encryption (optional, default: true)
    use_tls: true

    # Connection timeout in seconds (optional, default: 30)
    timeout: 30

  # -----------------------------------------------------------------------------
  # SendGrid Configuration (required if backend=sendgrid)
  # -----------------------------------------------------------------------------
  # sendgrid:
  #   api_key: ${SENDGRID_API_KEY}

  # -----------------------------------------------------------------------------
  # AWS SES Configuration (required if backend=ses)
  # -----------------------------------------------------------------------------
  # aws_ses:
  #   region: us-east-1
  #   access_key_id: ${AWS_ACCESS_KEY_ID}  # Optional, uses IAM role if not provided
  #   secret_access_key: ${AWS_SECRET_ACCESS_KEY}  # Optional


# ============================================================================
# Queue Configuration (optional)
# ============================================================================
# Celery background job processing settings

queue:
  # Redis URL for task queue broker (optional, default: redis://redis:6379/0)
  broker_url: redis://redis:6379/0

  # Redis URL for storing task results (optional, default: redis://redis:6379/1)
  result_backend: redis://redis:6379/1

  # Default queue name (optional, default: processing)
  default_queue: processing

  # Worker concurrency level (optional, default: 4)
  # Number of worker processes per container
  worker_concurrency: 4

  # Task timeout in seconds (optional, default: 3600)
  # Maximum time a task can run before being terminated
  task_timeout: 3600


# ============================================================================
# MinIO / S3 Object Storage Configuration (REQUIRED)
# ============================================================================
# Curatore v2 requires object storage. Filesystem storage is no longer supported.
# Backend connects directly to MinIO or S3 for all file operations.
#
# Start services with: ./scripts/dev-up.sh
# Initialize storage with: ./scripts/init_storage.sh
#
# IMPORTANT: For development, you need to:
#   1. MinIO starts automatically with backend services (no --profile needed)
#   2. Add "127.0.0.1 minio" to your /etc/hosts (or C:\Windows\System32\drivers\etc\hosts)
#      This allows your browser to access presigned URLs that use the "minio" hostname.
#   3. Run ./scripts/init_storage.sh to create buckets and set lifecycle policies
#   For production, configure public_endpoint to match your public S3/MinIO hostname.
#
# If not configured here, falls back to MINIO_* environment variables

minio:
  # Enable object storage (REQUIRED, default: true)
  # Object storage is required - no filesystem fallback
  enabled: true

  # MinIO/S3 server endpoint (host:port) for internal operations (required)
  # Examples:
  #   - MinIO (Docker): minio:9000
  #   - MinIO (Local): localhost:9000
  #   - AWS S3: s3.amazonaws.com
  #   - AWS S3 (regional): s3.us-west-2.amazonaws.com
  endpoint: minio:9000

  # Endpoint used to generate presigned URLs (optional)
  # Must be reachable from the backend container
  # Leave empty to use 'endpoint' value
  # presigned_endpoint:

  # Public endpoint for presigned URLs (optional)
  # The hostname that appears in presigned URLs for browser/client access
  # Leave empty for development (requires /etc/hosts entry: 127.0.0.1 minio)
  # Production: your-bucket.s3.amazonaws.com or custom domain
  # public_endpoint:

  # MinIO access key / AWS Access Key ID (required)
  # Recommended: Reference from environment for security
  # Should match MINIO_ROOT_USER for MinIO
  access_key: ${MINIO_ACCESS_KEY}

  # MinIO secret key / AWS Secret Access Key (required)
  # CRITICAL: Keep this secret! Reference from environment.
  # Should match MINIO_ROOT_PASSWORD for MinIO
  secret_key: ${MINIO_SECRET_KEY}

  # Use HTTPS for internal MinIO/S3 connections (optional, default: false)
  # - false: HTTP (development, internal networks, MinIO default)
  # - true: HTTPS (production, AWS S3, public networks)
  secure: false

  # Use HTTPS for presigned URLs (optional, defaults to 'secure' if not set)
  # - false: HTTP (development)
  # - true: HTTPS (production)
  # public_secure: false

  # Bucket for uploaded files (optional, default: curatore-uploads)
  bucket_uploads: curatore-uploads

  # Bucket for processed files (optional, default: curatore-processed)
  bucket_processed: curatore-processed

  # Bucket for temporary files (optional, default: curatore-temp)
  bucket_temp: curatore-temp

  # Presigned URL expiry in seconds (optional, default: 3600 = 1 hour)
  # Range: 60 seconds (1 min) to 86400 seconds (24 hours)
  # Frontend uploads/downloads use presigned URLs for direct storage access
  # Lower = more secure, higher = more convenient
  presigned_expiry: 3600


# ============================================================================
# OpenSearch Configuration (Native Full-Text Search)
# ============================================================================
# OpenSearch provides full-text search across all indexed content (uploads,
# SharePoint, web scrapes). Documents are automatically indexed after extraction.
#
# Quick Start:
#   1. Enable OpenSearch: set enabled: true below
#   2. Start with search profile: docker compose --profile search up -d
#   3. Access search at: http://localhost:3000/search
#
# Architecture:
#   - OpenSearch runs as a separate container (port 9200)
#   - Assets are indexed after successful extraction
#   - Indices are organization-scoped for multi-tenancy
#   - Full-text search with relevance scoring and highlighting
#
# External Hosting:
#   You can point to an externally hosted OpenSearch cluster:
#   - AWS OpenSearch Service: https://your-domain.region.es.amazonaws.com
#   - Self-hosted cluster: https://opensearch.your-domain.com
#   - Set username/password if authentication is enabled
#
# If not configured here, falls back to OPENSEARCH_* environment variables

opensearch:
  # Enable OpenSearch full-text search (optional, default: false)
  # Set to true to enable search functionality
  enabled: false

  # OpenSearch service URL (required if enabled)
  # Examples:
  #   - Docker: http://opensearch:9200
  #   - Local: http://localhost:9200
  #   - AWS OpenSearch: https://your-domain.region.es.amazonaws.com
  #   - External: https://opensearch.your-domain.com:9200
  service_url: http://opensearch:9200

  # Authentication (optional, leave empty for no auth)
  # Required for AWS OpenSearch or secured clusters
  username: ${OPENSEARCH_USERNAME:-}
  password: ${OPENSEARCH_PASSWORD:-}

  # Verify SSL certificates (optional, default: false)
  # - false: Disable SSL verification (development, self-signed certs)
  # - true: Verify SSL (production, AWS OpenSearch)
  verify_ssl: false

  # Index prefix for all Curatore indices (optional, default: curatore)
  # Indices are named: {prefix}-assets-{org_id}
  # Example: curatore-assets-550e8400-e29b-41d4-a716-446655440000
  index_prefix: curatore

  # Request timeout in seconds (optional, default: 30)
  # Increase for large indices or complex queries
  timeout: 30

  # Batch size for bulk indexing operations (optional, default: 100)
  # Used during reindex operations
  batch_size: 100

  # Maximum content length to index (optional, default: 100000 characters)
  # Longer documents are truncated for indexing
  # Increase for full document search, decrease for faster indexing
  max_content_length: 100000
